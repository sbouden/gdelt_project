{"paragraphs":[{"text":"%md\n\n## Requête 4\n\nDans ce notebook, nous construisons la requête 4:\n\n*dresser la cartographie des relations entre les pays d’après le ton des articles : pour chaque paire (pays1, pays2), calculer le nombre d’article, le ton moyen (aggrégations sur Année/Mois/Jour, filtrage par pays ou carré de coordonnées)*","user":"anonymous","dateUpdated":"2020-01-28T19:45:27+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Requête 4</h2>\n<p>Dans ce notebook, nous construisons la requête 4:</p>\n<p><em>dresser la cartographie des relations entre les pays d’après le ton des articles : pour chaque paire (pays1, pays2), calculer le nombre d’article, le ton moyen (aggrégations sur Année/Mois/Jour, filtrage par pays ou carré de coordonnées)</em></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1580240601279_-722398744","id":"20181212-102323_67420128","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:27+0000","dateFinished":"2020-01-28T19:45:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:21453"},{"text":"import org.apache.spark.sql.functions\nimport org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader","user":"anonymous","dateUpdated":"2020-01-28T19:45:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.functions\nimport org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\n"}]},"apps":[],"jobName":"paragraph_1580240601301_-1578055326","id":"20171217-232457_1732696781","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:27+0000","dateFinished":"2020-01-28T19:45:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21454"},{"text":"// Select files\nval pathToSelection = \"/tmp/gdelt/data/2019120[1-2]*\"","user":"anonymous","dateUpdated":"2020-01-28T19:45:28+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"pathToSelection: String = /tmp/gdelt/data/2019120[1-2]*\n"}]},"apps":[],"jobName":"paragraph_1580240601302_-2020127334","id":"20200118-162838_1638931284","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:28+0000","dateFinished":"2020-01-28T19:45:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21455"},{"text":"// define UDF functions\ndef toYear(s : String): Int = if (s.isEmpty) 0 else (s.slice(0, 0 + 4)).toInt\ndef toMonth(s : String): Int = if (s.isEmpty) 0 else (s.slice(4, 4 + 2)).toInt\ndef toDay(s : String): Int = if (s.isEmpty) 0 else (s.slice(6, 6 + 2)).toInt\n\ndef getTone(tones: String): Double = tones.split(\",\")(0).toDouble\n\n// define UDF\nval udfToYear = udf(toYear _)\nval udfToMonth = udf(toMonth _)\nval udfToDay = udf(toDay _)\n\nval udfGetTone = udf(getTone _)","user":"anonymous","dateUpdated":"2020-01-28T19:45:29+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"toYear: (s: String)Int\ntoMonth: (s: String)Int\ntoDay: (s: String)Int\ngetTone: (tones: String)Double\nudfToYear: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,IntegerType,Some(List(StringType)))\nudfToMonth: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,IntegerType,Some(List(StringType)))\nudfToDay: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,IntegerType,Some(List(StringType)))\nudfGetTone: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(StringType)))\n"}]},"apps":[],"jobName":"paragraph_1580240601302_509540519","id":"20200123-175716_1123407734","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:29+0000","dateFinished":"2020-01-28T19:45:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21456"},{"text":"// Load events\nval rddEventsEng = sc.binaryFiles(pathToSelection + \".export.CSV.zip\"). // charger quelques fichers via une regex\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\nval dfEventsEng = rddEventsEng.map(x => x.split(\"\\t\")).map(row => row.mkString(\";\")).map(x => x.split(\";\")).toDF()\n\n// Load events (Translated)\nval rddEventsTrans = sc.binaryFiles(pathToSelection + \"translation.export.CSV.zip\"). // charger quelques fichers via une regex\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\nval dfEventsTrans = rddEventsTrans.map(x => x.split(\"\\t\")).map(row => row.mkString(\";\")).map(x => x.split(\";\")).toDF()\n\n// make union\nval dfEvents = dfEventsEng.union(dfEventsTrans)","user":"anonymous","dateUpdated":"2020-01-28T19:45:30+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rddEventsEng: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[279] at flatMap at <console>:57\ndfEventsEng: org.apache.spark.sql.DataFrame = [value: array<string>]\nrddEventsTrans: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[284] at flatMap at <console>:72\ndfEventsTrans: org.apache.spark.sql.DataFrame = [value: array<string>]\ndfEvents: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [value: array<string>]\n"}]},"apps":[],"jobName":"paragraph_1580240601303_1318572036","id":"20200113-214349_421924857","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:30+0000","dateFinished":"2020-01-28T19:45:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21457"},{"text":"// Load mentions\nval rddMentionsEng = sc.binaryFiles(pathToSelection + \".mentions.CSV.zip\") // charger quelques fichers via une regex\n   .flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry)\n                .takeWhile{ case null => zis.close(); false\n                            case _ => true }\n                .flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\nval dfMentionsEng = rddMentionsEng.map(x => x.split(\"\\t\")).map(row => row.mkString(\";\")).map(x => x.split(\";\")).toDF()\n\nval rddMentionsTrans = sc.binaryFiles(pathToSelection + \".translation.mentions.CSV.zip\") // charger quelques fichers via une regex\n   .flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry)\n                .takeWhile{ case null => zis.close(); false \n                            case _ => true }\n                .flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\nval dfMentionsTrans= rddMentionsTrans.map(x => x.split(\"\\t\")).map(row => row.mkString(\";\")).map(x => x.split(\";\")).toDF()\n\n// make union\nval dfMentions = dfMentionsEng.union(dfMentionsTrans)","user":"anonymous","dateUpdated":"2020-01-28T19:45:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rddMentionsEng: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[289] at flatMap at <console>:57\ndfMentionsEng: org.apache.spark.sql.DataFrame = [value: array<string>]\nrddMentionsTrans: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[294] at flatMap at <console>:72\ndfMentionsTrans: org.apache.spark.sql.DataFrame = [value: array<string>]\ndfMentions: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [value: array<string>]\n"}]},"apps":[],"jobName":"paragraph_1580240601305_-1511736212","id":"20200123-175548_1034756314","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:32+0000","dateFinished":"2020-01-28T19:45:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21458"},{"text":"%md\n### Requête 4\n\ndresser la cartographie des relations entre les pays d’après le ton des articles : pour chaque paire (pays1, pays2), calculer le nombre d’article, le ton moyen (aggrégations sur Année/Mois/Jour, filtrage par pays ou carré de coordonnées)","user":"anonymous","dateUpdated":"2020-01-28T19:45:34+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Requête 4</h3>\n<p>dresser la cartographie des relations entre les pays d’après le ton des articles : pour chaque paire (pays1, pays2), calculer le nombre d’article, le ton moyen (aggrégations sur Année/Mois/Jour, filtrage par pays ou carré de coordonnées)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1580240601308_267080513","id":"20200113-215239_1349336337","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:34+0000","dateFinished":"2020-01-28T19:45:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21459"},{"text":"// Select columns and cast\nval dfEventsSelect = dfEvents\n    .withColumn(\"_tmp\", $\"value\")\n    .select($\"_tmp\".getItem(0).as(\"eventid\"),\n            udfToYear($\"_tmp\".getItem(1)).as(\"year\"),\n            udfToMonth($\"_tmp\".getItem(1)).as(\"month\"),\n            udfToDay($\"_tmp\".getItem(1)).as(\"day\"),\n            $\"_tmp\".getItem(7).as(\"actor1countrycode\"),\n            $\"_tmp\".getItem(17).as(\"actor2countrycode\"),\n            $\"_tmp\".getItem(34).as(\"avgtone\"),\n            $\"_tmp\".getItem(40).as(\"actor1geolat\"),\n            $\"_tmp\".getItem(41).as(\"actor1geolong\"),\n            $\"_tmp\".getItem(48).as(\"actor2geolat\"),\n            $\"_tmp\".getItem(49).as(\"actor2geolong\"))\n    .withColumn(\"eventid\", $\"eventid\".cast(\"Int\"))        \n    .withColumn(\"avgtone\", $\"avgtone\".cast(\"Float\"))\n    .withColumn(\"actor1geolat\", $\"actor1geolat\".cast(\"Float\"))\n    .withColumn(\"actor1geolong\", $\"actor1geolong\".cast(\"Float\"))\n    .withColumn(\"actor2geolat\", $\"actor2Geolat\".cast(\"Float\"))\n    .withColumn(\"actor2geolong\", $\"actor2geolong\".cast(\"Float\"))\n    .filter($\"actor1countrycode\" !== \"\")\n    .filter($\"actor2countrycode\" !== \"\")\n    \n\ndfEventsSelect.printSchema()","user":"anonymous","dateUpdated":"2020-01-28T19:45:34+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there were two deprecation warnings; re-run with -deprecation for details\nroot\n |-- eventid: integer (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- actor1countrycode: string (nullable = true)\n |-- actor2countrycode: string (nullable = true)\n |-- avgtone: float (nullable = true)\n |-- actor1geolat: float (nullable = true)\n |-- actor1geolong: float (nullable = true)\n |-- actor2geolat: float (nullable = true)\n |-- actor2geolong: float (nullable = true)\n\ndfEventsSelect: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [eventid: int, year: int ... 9 more fields]\n"}]},"apps":[],"jobName":"paragraph_1580240601310_-23884717","id":"20200113-215406_1630690280","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:34+0000","dateFinished":"2020-01-28T19:45:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21460"},{"text":"// sort pair of country\nval dfEventsTmp1 = dfEventsSelect.filter($\"actor1countrycode\" <= $\"actor2countrycode\")\nval dfEventsTmp2 = dfEventsSelect\n    .filter(!($\"actor1countrycode\" > $\"actor2countrycode\"))\n    .withColumnRenamed(\"actor1countrycode\", \"tmp\")\n    .withColumnRenamed(\"actor2countrycode\", \"actor1countrycode\")\n    .withColumnRenamed(\"tmp\", \"actor2countrycode\")\n\nval dfEventsSorted = dfEventsTmp1.union(dfEventsTmp2)\n\ndfEventsSorted.show()","user":"anonymous","dateUpdated":"2020-01-28T19:45:35+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+----+-----+---+-----------------+-----------------+----------+------------+-------------+------------+-------------+\n|  eventid|year|month|day|actor1countrycode|actor2countrycode|   avgtone|actor1geolat|actor1geolong|actor2geolat|actor2geolong|\n+---------+----+-----+---+-----------------+-----------------+----------+------------+-------------+------------+-------------+\n|890116322|2019|   11|  1|              CHN|              VNM|  -4.92228|        40.0|        127.0|        40.0|        127.0|\n|890116411|2019|   12|  1|              AFG|              GBR|  -6.91221|        51.5|    -0.116667|        51.5|    -0.116667|\n|890116412|2019|   12|  1|              AFG|              GBR|  -6.91221|        33.0|         66.0|        51.5|    -0.116667|\n|890116413|2019|   12|  1|              AFG|              GBR|  -6.91221|        33.0|         44.0|        51.5|    -0.116667|\n|890116429|2019|   12|  1|              BOL|              BOL|   -7.1875|       -17.0|        -65.0|       -17.0|        -65.0|\n|890116430|2019|   12|  1|              BOL|              BOL|-1.3182675|        48.0|         68.0|        48.0|         68.0|\n|890116445|2019|   12|  1|              CHL|              CHL|-5.9171596|      -33.45|     -70.6667|      -33.45|     -70.6667|\n|890116446|2019|   12|  1|              CHL|              CHL|-5.9171596|      -33.45|     -70.6667|      -33.45|     -70.6667|\n|890116450|2019|   12|  1|              CHN|              CHN| 2.0833333|     39.9289|      116.388|     39.9289|      116.388|\n|890116451|2019|   12|  1|              CHN|              GRC|     3.125|        35.0|        105.0|        39.0|         22.0|\n|890116452|2019|   12|  1|              CHN|              GRC|     3.125|        39.0|         22.0|        39.0|         22.0|\n|890116453|2019|   12|  1|              CHN|              GRC|     3.125|        35.0|        105.0|        39.0|         22.0|\n|890116454|2019|   12|  1|              CHN|              GRC|     3.125|        39.0|         22.0|        39.0|         22.0|\n|890116492|2019|   12|  1|              CUB|              CUB|-5.9171596|     23.1319|     -82.3642|     23.1319|     -82.3642|\n|890116493|2019|   12|  1|              CUB|              CUB|-5.9171596|     23.1319|     -82.3642|     23.1319|     -82.3642|\n|890116536|2019|   12|  1|              EGY|              TUR|-0.7751938|     37.9833|      23.7333|       30.05|        31.25|\n|890116537|2019|   12|  1|              EGY|              TUR|-0.7751938|     37.9833|      23.7333|       30.05|        31.25|\n|890116538|2019|   12|  1|              EGY|              TUR|-0.7751938|     37.9833|      23.7333|     37.9833|      23.7333|\n|890116543|2019|   12|  1|              ESP|              ESP|-5.4455447|        40.4|     -3.68333|        40.4|     -3.68333|\n|890116544|2019|   12|  1|              ESP|              ESP|-5.4455447|         9.0|        -80.0|        40.4|     -3.68333|\n+---------+----+-----+---+-----------------+-----------------+----------+------------+-------------+------------+-------------+\nonly showing top 20 rows\n\ndfEventsTmp1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [eventid: int, year: int ... 9 more fields]\ndfEventsTmp2: org.apache.spark.sql.DataFrame = [eventid: int, year: int ... 9 more fields]\ndfEventsSorted: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [eventid: int, year: int ... 9 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=21"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1580240601311_615134510","id":"20200123-182633_1444090578","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:35+0000","dateFinished":"2020-01-28T19:45:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21461"},{"text":"// Select columns and cast\nval dfMentionsSelect = dfMentions\n    .withColumn(\"_tmp\", $\"value\")\n    .select($\"_tmp\".getItem(0).as(\"eventid\"),\n            $\"_tmp\".getItem(5).as(\"mentionid\"))\n    .withColumn(\"eventid\", $\"eventid\".cast(\"Int\"))\n\ndfMentionsSelect.printSchema()","user":"anonymous","dateUpdated":"2020-01-28T19:45:36+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- eventid: integer (nullable = true)\n |-- mentionid: string (nullable = true)\n\ndfMentionsSelect: org.apache.spark.sql.DataFrame = [eventid: int, mentionid: string]\n"}]},"apps":[],"jobName":"paragraph_1580240601311_1753262637","id":"20200123-180053_914150778","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:36+0000","dateFinished":"2020-01-28T19:45:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21462"},{"text":"val dfMentionsAgg = dfMentionsSelect\n    .groupBy(\"eventid\")\n    .agg(countDistinct($\"mentionid\").as(\"numarticles\"))\n\ndfMentionsAgg.show(10) ","user":"anonymous","dateUpdated":"2020-01-28T19:45:37+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+-----------+\n|  eventid|numarticles|\n+---------+-----------+\n|890023001|        149|\n|890083586|        146|\n|890151386|          1|\n|890197802|         15|\n|890353646|          2|\n|890344945|          1|\n|890138478|         28|\n|890105775|          2|\n|890154852|        157|\n|890103420|          2|\n+---------+-----------+\nonly showing top 10 rows\n\ndfMentionsAgg: org.apache.spark.sql.DataFrame = [eventid: int, numarticles: bigint]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=22"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1580240601312_471390513","id":"20200123-180606_902979851","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:45:37+0000","dateFinished":"2020-01-28T19:46:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21463"},{"text":"val request4 = dfMentionsAgg\n    .join(dfEventsSorted, \"eventid\")\n    .select(\"actor1countrycode\", \"actor2countrycode\",\n            \"day\", \"month\", \"year\", \"avgtone\", \"numarticles\")","user":"anonymous","dateUpdated":"2020-01-28T19:46:17+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"request4: org.apache.spark.sql.DataFrame = [actor1countrycode: string, actor2countrycode: string ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1580240601312_827955283","id":"20200123-185035_1252629434","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:46:17+0000","dateFinished":"2020-01-28T19:46:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21464"},{"text":"request4.show()","user":"anonymous","dateUpdated":"2020-01-28T19:46:17+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------+-----------------+---+-----+----+----------+-----------+\n|actor1countrycode|actor2countrycode|day|month|year|   avgtone|numarticles|\n+-----------------+-----------------+---+-----+----+----------+-----------+\n|              JPN|              JPN|  1|   11|2019| 2.7173913|          2|\n|              JPN|              JPN|  1|   11|2019| 2.7173913|          2|\n|              AFG|              USA|  1|   12|2019| 1.3333334|          1|\n|              AFG|              USA|  1|   12|2019| 1.3333334|          1|\n|              PRT|              USA|  1|   12|2019| 1.7334778|          1|\n|              PRT|              USA|  1|   12|2019| 1.7334778|          1|\n|              MLT|              USA|  1|   12|2019|-10.245902|          1|\n|              MLT|              USA|  1|   12|2019|-10.245902|          1|\n|              USA|              USA|  1|   12|2019|  4.103165|          1|\n|              USA|              USA|  1|   12|2019|  4.103165|          1|\n|              AUS|              NMR|  1|   12|2019| -2.805516|          1|\n|              AUS|              NMR|  1|   12|2019| -2.805516|          1|\n|              GBR|              GBR|  1|   12|2019|-15.555555|          1|\n|              GBR|              GBR|  1|   12|2019|-15.555555|          1|\n|              VNM|              VNM|  1|   12|2019| -7.352941|          1|\n|              VNM|              VNM|  1|   12|2019| -7.352941|          1|\n|              USA|              USA|  1|   12|2019|-1.1873351|          1|\n|              USA|              USA|  1|   12|2019|-1.1873351|          1|\n|              CHN|              USA|  1|   12|2019|-6.9444447|          2|\n|              CHN|              USA|  1|   12|2019|-6.9444447|          2|\n+-----------------+-----------------+---+-----+----+----------+-----------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=23"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1580240601313_-1833813855","id":"20200123-190005_1285207976","dateCreated":"2020-01-28T19:43:21+0000","dateStarted":"2020-01-28T19:46:17+0000","dateFinished":"2020-01-28T19:47:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:21465"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1580240777780_-1742403649","id":"20200128-194617_62193696","dateCreated":"2020-01-28T19:46:17+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:21466"}],"name":"gdeltRequest4Local","id":"2F2BPTNS6","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[],"cassandra:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}